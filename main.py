# -*- coding: utf-8 -*-
"""VQVAE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iIkvgg76Gp4RHZVM2gpwa94kftKHkdG_
"""

#!pip install --force-reinstall git+https://github.com/vermeille/Torchelie
#!pip install crayons visdom lpips

import os
if not os.path.exists('download.zip'):
    os.system("wget https://cloud.vermeille.fr/s/36dOOpeBn7aIvcZ/download -O download.zip")
if not os.path.exists('FCUNIST'):
    os.system("unzip download.zip &> /dev/null")

import math

import torchelie as tch
from torchelie.nn import VQ, SelfAttention2d
from torchelie.utils import kaiming, xavier

import torch
import torch.nn as nn
import torch.nn.functional as F

import torchvision
import torchvision.transforms as TF
from torchelie.recipes import TrainAndTest
import torchelie.callbacks as tcb

from visdom import Visdom

def Conv(in_ch, out_ch, ks):
    return nn.Conv2d(in_ch, out_ch, ks, padding=ks // 2)


def ConvBNRelu(in_ch, out_ch, ks):
    return nn.Sequential(
            Conv(in_ch, out_ch, ks),
            nn.BatchNorm2d(out_ch, affine=True),
            nn.ReLU(inplace=False),
        )


class PosEnc(nn.Module):
    def __init__(self, *shape):
        super().__init__()
        self.pos = nn.Parameter(torch.zeros(*shape))

    def forward(self, x):
        return x + self.pos


class Res(nn.Module):
    def __init__(self, mod):
        super(Res, self).__init__()
        self.go = mod

    def forward(self, x):
        return self.go(x) + x


class ResBlk(nn.Module):
    def __init__(self, ch):
        super(ResBlk, self).__init__()
        self.go = nn.Sequential(
                ConvBNRelu(ch, ch, 3),
                ConvBNRelu(ch, ch, 3),
            )

    def forward(self, x):
        return self.go(x) + x

class NormChannel(nn.Module):
    def forward(self, x):
        return F.normalize(x, dim=1)

class RMSNorm(nn.Module):
    def __init__(self, dim, eps=1e-8):
        super().__init__()
        self.scale = nn.Parameter(torch.ones(dim, 1, 1))

        self.eps = eps

    def forward(self, x):
        return x * torch.rsqrt(x.pow(2).mean(dim=1, keepdim=True) + self.eps) * self.scale

class Encoder(nn.Module):
    def __init__(self, arch, hidden=128, codebook_size=1024, vq_dim=8):
        super(Encoder, self).__init__()
        layers = [
            Conv(3, hidden, 5),
            nn.BatchNorm2d(hidden, affine=True),
            nn.ReLU(inplace=True),
        ]

        self.start_hidden = hidden
        for l in arch:
            ch = min(512, hidden)
            if l == 'r':
                layers.append(ResBlk(ch))
            elif l == 'q':
                layers.append(PosEnc(ch, 8, 8))
                layers.append(Res(nn.Sequential(RMSNorm(ch), SelfAttention2d(ch, ch // 32, ch)))),
                layers.append(xavier(nn.Conv2d(ch, vq_dim, 3, stride=1,
                    padding=1)))
            elif l == 'p':
                nxt_hidden = min(512, hidden * 2)
                if ch >= 256:
                    layers.append(Res(nn.Sequential(RMSNorm(ch), SelfAttention2d(ch, ch // 32, ch)))),
                layers.append(xavier(nn.Conv2d(ch, nxt_hidden, 3, stride=2, padding=1)))
                layers.append(nn.BatchNorm2d(nxt_hidden, affine=True))
                hidden = nxt_hidden
        self.end_hidden = hidden

        self.layers = nn.ModuleList(layers)

    def forward(self, x, y=None, ret_idx=False):
        qs = []
        idxs = []
        for m in self.layers:
            if isinstance(m, VQ):
                x, idx = m(x)
                qs.append(x.detach())
                idxs.append(idx)
            else:
                x = m(x)

        return x
        if ret_idx:
            return qs[0], idxs[0]
        else:
            return qs[0]



class Decoder(nn.Module):
    def __init__(self, arch, hidden=128, vq_dim=8):
        super(Decoder, self).__init__()
        layers = [
            xavier(nn.Conv2d(vq_dim, min(512, hidden), 3, padding=1)),
            nn.BatchNorm2d(hidden, affine=True),
            PosEnc(min(512, hidden), 8, 8),
            Res(nn.Sequential(RMSNorm(hidden), SelfAttention2d(min(512, hidden), min(512, hidden) // 32, min(512, hidden)))),
        ]

        for l in arch:
            ch = min(512, hidden)
            if l == 'r':
                layers.append(ResBlk(ch))
            elif l == 'u':
                nxt_hidden = hidden // 2
                if False:
                    layers.append(nn.ConvTranspose2d(hidden, hidden, 4, stride=2, padding=1))#nn.UpsamplingNearest2d(scale_factor=2))
                elif True:
                    layers.append(nn.UpsamplingBilinear2d(scale_factor=2))
                    layers.append(xavier(nn.Conv2d(ch, min(512, nxt_hidden), 3, padding=1)))
                    layers.append(nn.BatchNorm2d(nxt_hidden, affine=True))
                else:
                    layers.append(nn.PixelShuffle(2))
                    layers.append(xavier(nn.Conv2d(ch // 4, min(512, nxt_hidden), 3, padding=1)))
                    layers.append(nn.BatchNorm2d(nxt_hidden, affine=True))
                hidden = nxt_hidden

        layers += [
            nn.BatchNorm2d(hidden, affine=True),
            xavier(Conv(hidden, 3, 3)),
        ]

        self.layers = nn.ModuleList(layers)

    def forward(self, x):
        for m in self.layers:
            x = m(x)

        print(x.std())
        return torch.sigmoid(x)


def AE(enc, dec, hidden=64, vq_dim=8):
    enc = Encoder(enc, hidden, vq_dim=vq_dim)
    vq = VQ(vq_dim, 1024, dim=1, max_age=10, space="angular", return_indices=False)
    return nn.Sequential(enc, vq, Decoder(dec, enc.end_hidden, vq_dim=vq_dim))


def AE_initialize(ae):
    for m in ae.modules():
        if isinstance(m, nn.Conv2d):
            nn.init.kaiming_uniform_(m.weight, mode='fan_in', a=0.2)
            nn.init.constant_(m.bias, 0)
        if isinstance(m, nn.BatchNorm2d):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)
    return ae

def baseline_256():
    return AE('rprprprrprrq', 'rrrurrurrrurrrur', hidden=32, vq_dim=16)

SZ = 128
tfms = TF.Compose([
    TF.Resize(SZ),
    TF.CenterCrop(SZ),
    TF.RandomHorizontalFlip(),
    TF.ToTensor(),
])

#ds = torchvision.datasets.CelebA('~/.cache/torch/celeba', download=True, transform=tfms)
#ds = torchvision.datasets.Food101('~/.cache/torch/food101', download=True, transform=tfms)
ds = torchvision.datasets.ImageFolder('FCUNIST/train', transform=tfms)
print('dataset size:', len(ds))
dl = torch.utils.data.DataLoader(ds,
                                 batch_size=64,
                                 shuffle=True,
                                 num_workers=16,
                                 pin_memory=True)
dlt = torch.utils.data.DataLoader(torch.utils.data.Subset(
    ds, list(int(len(ds) * i / 64) for i in range(64))),
                                  batch_size=64,
                                  shuffle=False,
                                  num_workers=16,
                                  pin_memory=True)

import lpips
ploss = lpips.LPIPS(net='vgg', lpips=False).cuda()
device = 'cuda'
m = baseline_256().to(device)
print(m)
lr=1e-4
#adv_loss = AdvLoss(1e-3).to(device)
print(sum(p.numel() for p in m.parameters()) / 1e6, "M params")

def train_fun(batch):
  x = batch[0]
  recon = m(x* 2 - 1)
  loss = ploss.forward(recon * 2 - 1, x * 2 - 1).mean()
  loss.backward()
  return {"loss": loss.item()}

@torch.no_grad()
def test_fun(batch):
  x = batch[0]
  enc = m[0](x * 2 - 1)
  m[1].return_indices = True
  quant, idxs = m[1](enc)
  m[1].return_indices = False
  recon = m[2](quant)
  idxs = idxs.squeeze(1)
  idxs[:, 2:3] = torch.randint(0, 1024, (x.shape[0], 1, 8), device=idxs.device)
  altered = m[2](m[1](idxs))
  return {"recon": recon, "altered": altered}

opt = torch.optim.AdamW(m.parameters(), lr=lr)
recipe = TrainAndTest(m, train_fun, test_fun, dl, dlt, log_every=1, test_every=20, visdom_env=None)

recipe.callbacks.cbs[-1][0].vis = Visdom(env=f"vqvae-{lr}", server="https://visdom.vermeille.fr", port=443)
recipe.callbacks.cbs[-1][0].vis.close()
recipe.callbacks.add_callbacks([
    tcb.Optimizer(opt, log_lr=True, centralize_grad=False),
    tcb.Log('loss', 'loss'),
])
recipe.test_loop.callbacks.cbs[-1][0].vis = Visdom(env=f"vqvae-{lr}", server="https://visdom.vermeille.fr", port=443)
recipe.test_loop.callbacks.add_callbacks([
    tcb.Log('recon', 'recon'),
    tcb.Log('altered', 'altered'),
])
recipe.to(device)
recipe.run(30)




